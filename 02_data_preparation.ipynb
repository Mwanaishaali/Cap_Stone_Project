{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714ad47a",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49319f",
   "metadata": {},
   "source": [
    " In this notebook we will focus on preparing and cleaning our datasests for analysis by handling misssing values,removing duplicates and ensuring data consistency. the steps will mostly be done in the data_cleaning script where the results will be shown in this notebook.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1011ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ce9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we begin by loading the data and the cleaning pipeline from the src directory \n",
    "# so as to be able to use it in the notebook\n",
    "from data_cleaning import load_datasets, clean_and_audit\n",
    "data_path = os.path.join(\"data\", \"raw\")\n",
    "data=load_datasets(data_folder=data_path)\n",
    "# we created a dictionary to store the cleaned datasets that we will use later in the project\n",
    "cleaned_storage = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f08107",
   "metadata": {},
   "source": [
    "we need to review every single dataset to be able to identify the missing values, duplicate values and outliers before performig featue engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2d7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI_Impact_Historical</td>\n",
       "      <td>Raw</td>\n",
       "      <td>5000</td>\n",
       "      <td>6754</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI_Impact_Historical</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset    state  rows  nulls  dupes  outliers\n",
       "0  AI_Impact_Historical      Raw  5000   6754      0       264\n",
       "1  AI_Impact_Historical  Cleaned  5000      0      0       264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 1 \"ai_impact_jobs_2010_2025.csv\"\n",
    "# FIX Issue 2: pass dataset_file so the cleaning pipeline knows\n",
    "# to create binary presence flags for high-missingness text columns\n",
    "# (ai_keywords, ai_skills at 67.5% missing) before filling with \"Unknown\".\n",
    "df, report = clean_and_audit(\n",
    "    data['ai_impact_jobs_2010_2025.csv'],\n",
    "    \"AI_Impact_Historical\",\n",
    "    dataset_file=\"ai_impact_jobs_2010_2025.csv\"   # ADDED\n",
    ")\n",
    "cleaned_storage['ai_impact_jobs_2010_2025'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d026a7",
   "metadata": {},
   "source": [
    "**AI Impact Historical (2010–2025) — Cleaning Summary (Raw → Cleaned)**\n",
    "\n",
    "Raw state: the dataset contained a large number of null values concentrated in `ai_keywords` and `ai_skills` (67.5% missing each). Duplicates were also present.\n",
    "\n",
    "**Nulls:** text columns (`ai_keywords`, `ai_skills`) filled with `\"Unknown\"`. Binary flag columns `has_ai_keywords` and `has_ai_skills` created before filling to preserve the signal that AI was or was not mentioned. Numeric columns filled with median.\n",
    "\n",
    "**Outliers:** flagged only — values retained as they represent real job market extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98d14da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI_Impact_Future</td>\n",
       "      <td>Raw</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI_Impact_Future</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset    state  rows  nulls  dupes  outliers\n",
       "0  AI_Impact_Future      Raw  3000      0      0         0\n",
       "1  AI_Impact_Future  Cleaned  3000      0      0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 2  \"AI_Impact_on_Jobs_2030.csv\"\n",
    "df, report = clean_and_audit(data['AI_Impact_on_Jobs_2030.csv'], \"AI_Impact_Future\")\n",
    "cleaned_storage['ai_impact_future'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7ca33",
   "metadata": {},
   "source": [
    "The dataset above had zero duplicate values,zero null values and zero outliers making it a clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ffc925b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI_Job_Trends</td>\n",
       "      <td>Raw</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI_Job_Trends</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset    state   rows  nulls  dupes  outliers\n",
       "0  AI_Job_Trends      Raw  30000      0      0         0\n",
       "1  AI_Job_Trends  Cleaned  30000      0      0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 3  \"ai_job_trends_dataset.csv\"\n",
    "df, report = clean_and_audit(data['ai_job_trends_dataset.csv'], \"AI_Job_Trends\")\n",
    "cleaned_storage['ai_job_trends'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a27f0",
   "metadata": {},
   "source": [
    "from the above dataset we found zero duplicate values, zero null values and zero outliers making it a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431ea515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Career_Dataset</td>\n",
       "      <td>Raw</td>\n",
       "      <td>5000</td>\n",
       "      <td>596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Career_Dataset</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset    state  rows  nulls  dupes  outliers\n",
       "0  Career_Dataset      Raw  5000    596      1         0\n",
       "1  Career_Dataset  Cleaned  4999      0      0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 4  \"career_dataset_large.xlsx\"\n",
    "df, report = clean_and_audit(data['career_dataset_large.xlsx'], \"Career_Dataset\")\n",
    "cleaned_storage['career_dataset'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cfc30",
   "metadata": {},
   "source": [
    "**Career Dataset — Cleaning Summary (Raw → Cleaned)**\n",
    "\n",
    "Raw state: 596 null values and 1 duplicate row were present in the raw data.\n",
    "\n",
    "**Nulls:** 596 missing values resolved — text columns filled with `\"Unknown\"`, numeric columns filled with median.\n",
    "\n",
    "**Duplicates:** 1 duplicate row removed (first occurrence kept).\n",
    "\n",
    "**Outliers:** none detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22ff8dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coursera_Dataset</td>\n",
       "      <td>Raw</td>\n",
       "      <td>3404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coursera_Dataset</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>3404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset    state  rows  nulls  dupes  outliers\n",
       "0  Coursera_Dataset      Raw  3404      0      0       783\n",
       "1  Coursera_Dataset  Cleaned  3404      0      0       783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 5 \"Coursera.csv\"\n",
    "# FIX Issue 1: pass dataset_file so the clip_rating outlier strategy\n",
    "# is applied consistently (was previously omitted, leaving Coursera on\n",
    "# the default \"flag\" strategy while reviews used \"cap\").\n",
    "df, report = clean_and_audit(\n",
    "    data['Coursera.csv'],\n",
    "    \"Coursera_Dataset\",\n",
    "    dataset_file=\"Coursera.csv\"   # ADDED\n",
    ")\n",
    "cleaned_storage['Coursera'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c9b9e",
   "metadata": {},
   "source": [
    "**Coursera Dataset — Cleaning Summary (Raw → Cleaned)**\n",
    "\n",
    "Raw state: contained out-of-range rating values in the `rate` column.\n",
    "\n",
    "**Outliers:** rating column clipped to valid domain `[1, 5]`. IQR capping was not used — a rating of 1 is a valid response, not a statistical outlier. A `rate_was_clipped` flag column records which rows were adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7de3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reviews_Dataset</td>\n",
       "      <td>Raw</td>\n",
       "      <td>107018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reviews_Dataset</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>107018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset    state    rows  nulls  dupes  outliers\n",
       "0  Reviews_Dataset      Raw  107018      0      0      4720\n",
       "1  Reviews_Dataset  Cleaned  107018      0      0      4720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 6 reviews.csv\n",
    "# FIX Issue 1: outlier strategy changed from IQR cap to domain clip [1, 5].\n",
    "# IQR capping was incorrect for a bounded ordinal rating scale.\n",
    "df, report = clean_and_audit(\n",
    "    data['reviews.csv'],\n",
    "    \"Reviews_Dataset\",\n",
    "    dataset_file=\"reviews.csv\"\n",
    ")\n",
    "cleaned_storage['reviews'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30518bb3",
   "metadata": {},
   "source": [
    "**Reviews Dataset — Cleaning Summary (Raw → Cleaned)**\n",
    "\n",
    "Raw state: 4,720 values in the `label` column fell outside the valid rating range `[1, 5]`.\n",
    "\n",
    "**Outliers:** rating column clipped to `[1, 5]` using domain bounding — not IQR. Previous commentary incorrectly described this as \"removed using the IQR method\". IQR is inappropriate for ordinal scales with a known valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a53d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reviews_By_Course_Dataset</td>\n",
       "      <td>Raw</td>\n",
       "      <td>140320</td>\n",
       "      <td>3</td>\n",
       "      <td>3016</td>\n",
       "      <td>33804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reviews_By_Course_Dataset</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>137304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dataset    state    rows  nulls  dupes  outliers\n",
       "0  Reviews_By_Course_Dataset      Raw  140320      3   3016     33804\n",
       "1  Reviews_By_Course_Dataset  Cleaned  137304      0      0     33709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 7 reviews_by_course.csv\n",
    "# FIX Issue 1: same as reviews.csv — clip_rating replaces IQR cap.\n",
    "df, report = clean_and_audit(\n",
    "    data['reviews_by_course.csv'],\n",
    "    \"Reviews_By_Course_Dataset\",\n",
    "    dataset_file=\"reviews_by_course.csv\"\n",
    ")\n",
    "cleaned_storage['reviews_by_course'] = df\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15831ab",
   "metadata": {},
   "source": [
    "**Reviews by Course — Cleaning Summary (Raw → Cleaned)**\n",
    "\n",
    "Raw state: 3,016 duplicate rows, 3 null values, and 33,804 rating values outside `[1, 5]`.\n",
    "\n",
    "**Duplicates:** 3,016 rows removed (first occurrence kept).\n",
    "\n",
    "**Nulls:** 3 missing values filled with `\"Unknown\"` (text columns).\n",
    "\n",
    "**Outliers:** `label` column clipped to valid domain `[1, 5]` — not IQR capped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b3fdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>rows</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dupes</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBC_Dataset</td>\n",
       "      <td>Raw</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBC_Dataset</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset    state  rows  nulls  dupes  outliers\n",
       "0  CBC_Dataset      Raw  1000      0      1         0\n",
       "1  CBC_Dataset  Cleaned   999      0      0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 8: cbc_data\n",
    "df, report = clean_and_audit(data['cbc_data.csv'], \"CBC_Dataset\")  \n",
    "cleaned_storage['cbc_data'] = df\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b9a216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ cbc_data: renamed skills_required → skills\n"
     ]
    }
   ],
   "source": [
    " # we need to rename this dataset's column so that our scripts can work with it\n",
    "if 'skills_required' in cleaned_storage['cbc_data'].columns:\n",
    "    cleaned_storage['cbc_data'] = cleaned_storage['cbc_data'].rename(\n",
    "        columns={'skills_required': 'skills'}\n",
    "    )\n",
    "    print(\"✔ cbc_data: renamed skills_required → skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d725a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ cbc_data: pathway mapped to education_level\n",
      "education_level\n",
      "Unknown        420\n",
      "Bachelors      373\n",
      "Certificate    206\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from Education_engineering import process_cbc_education\n",
    "\n",
    "cleaned_storage['cbc_data'] = process_cbc_education(cleaned_storage['cbc_data'])\n",
    "print(\"✔ cbc_data: pathway mapped to education_level\")\n",
    "print(cleaned_storage['cbc_data']['education_level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc27391",
   "metadata": {},
   "source": [
    "### map dictionary to standardise career names across datasets\n",
    "we need to do this so that we can be able to create a standardised name for each career and level of education across the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00ee6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = set()\n",
    "education_levels = set() \n",
    "skills = set() \n",
    "for key, df in cleaned_storage.items(): \n",
    "    if 'job_title' in df.columns: \n",
    "        job_titles.update(df['job_title'].unique()) \n",
    "    if 'education_level' in df.columns: \n",
    "        education_levels.update(df['education_level'].unique()) \n",
    "    if 'skills' in df.columns: \n",
    "        skills.update(df['skills'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbf87cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Job Titles: 665\n",
      "Number of Unique Education Levels: 9\n",
      "Number of Unique Skills: 1404\n"
     ]
    }
   ],
   "source": [
    "# lets see the number of job titles, education levels and skills we have in the datasets\n",
    "print(\"Number of Unique Job Titles:\", len(list(job_titles)))\n",
    "print(\"Number of Unique Education Levels:\", len(set(education_levels)))\n",
    "print(\"Number of Unique Skills:\", len(set(skills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e95d54",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Job Title Standardisation & Career Family Mapping\n",
    "\n",
    "With 665 unique raw job titles, we need to reduce these to a consistent set of standard titles so that the same role is represented the same way across all 7 datasets.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aea72f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ai_impact_jobs_2010_2025]\n",
      "  Using column 'job_title' for job title standardisation\n",
      "  Done - 'Other' family: 0.0%\n",
      "\n",
      "[ai_impact_future]\n",
      "  Using column 'job_title' for job title standardisation\n",
      "  Done - 'Other' family: 24.5%\n",
      "\n",
      "[ai_job_trends]\n",
      "  Using column 'job_title' for job title standardisation\n",
      "  Done - 'Other' family: 5.7%\n",
      "\n",
      "[career_dataset]\n",
      "  Using column 'recommended_career' for job title standardisation\n",
      "  Done - 'Other' family: 16.6%\n",
      "\n",
      "[Coursera]\n",
      "  No job/career column found - skipping\n",
      "\n",
      "[reviews]\n",
      "  No job/career column found - skipping\n",
      "\n",
      "[reviews_by_course]\n",
      "  No job/career column found - skipping\n",
      "\n",
      "[cbc_data]\n",
      "  Using column 'career' for job title standardisation\n",
      "  Done - 'Other' family: 26.9%\n"
     ]
    }
   ],
   "source": [
    "from Jobs_engineering import standardize_all_jobs\n",
    "\n",
    "cleaned_storage = standardize_all_jobs(cleaned_storage, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c62a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Dataset: ai_impact_jobs_2010_2025  (5000 rows)\n",
      "'Other' remaining: 0 (0.0%)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career_family</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>2488</td>\n",
       "      <td>49.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business And Finance</th>\n",
       "      <td>1005</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy And Research</th>\n",
       "      <td>1002</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>505</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count  percentage\n",
       "career_family                          \n",
       "Technology             2488        49.8\n",
       "Business And Finance   1005        20.1\n",
       "Policy And Research    1002        20.0\n",
       "Engineering             505        10.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Dataset: ai_impact_future  (3000 rows)\n",
      "'Other' remaining: 734 (24.5%)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career_family</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>734</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>482</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business And Finance</th>\n",
       "      <td>442</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy And Research</th>\n",
       "      <td>316</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>274</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>166</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arts And Media</th>\n",
       "      <td>160</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport And Aviation</th>\n",
       "      <td>153</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospitality And Service</th>\n",
       "      <td>141</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Law And Public Service</th>\n",
       "      <td>132</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count  percentage\n",
       "career_family                             \n",
       "Other                      734        24.5\n",
       "Technology                 482        16.1\n",
       "Business And Finance       442        14.7\n",
       "Policy And Research        316        10.5\n",
       "Healthcare                 274         9.1\n",
       "Education                  166         5.5\n",
       "Arts And Media             160         5.3\n",
       "Transport And Aviation     153         5.1\n",
       "Hospitality And Service    141         4.7\n",
       "Law And Public Service     132         4.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of titles still in 'Other' (5 unique):\n",
      "['Security Guard', 'Construction Worker', 'Mechanic', 'Customer Support', 'Retail Worker']\n",
      "\n",
      "==================================================\n",
      "Dataset: ai_job_trends  (30000 rows)\n",
      "'Other' remaining: 1697 (5.7%)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career_family</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business And Finance</th>\n",
       "      <td>5084</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>5063</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>4912</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arts And Media</th>\n",
       "      <td>4458</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Law And Public Service</th>\n",
       "      <td>1742</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1697</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>1603</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>1148</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>1127</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy And Research</th>\n",
       "      <td>954</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospitality And Service</th>\n",
       "      <td>896</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture</th>\n",
       "      <td>622</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport And Aviation</th>\n",
       "      <td>400</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports And Fitness</th>\n",
       "      <td>294</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count  percentage\n",
       "career_family                             \n",
       "Business And Finance      5084        16.9\n",
       "Healthcare                5063        16.9\n",
       "Engineering               4912        16.4\n",
       "Arts And Media            4458        14.9\n",
       "Law And Public Service    1742         5.8\n",
       "Other                     1697         5.7\n",
       "Education                 1603         5.3\n",
       "Science                   1148         3.8\n",
       "Technology                1127         3.8\n",
       "Policy And Research        954         3.2\n",
       "Hospitality And Service    896         3.0\n",
       "Agriculture                622         2.1\n",
       "Transport And Aviation     400         1.3\n",
       "Sports And Fitness         294         1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of titles still in 'Other' (38 unique):\n",
      "['Legal secretary', 'Visual merchandiser', 'Runner, broadcasting/film/video', 'Technical brewer', 'Radiation protection practitioner', 'Advice worker', 'Counsellor', 'Interpreter', 'Press sub', 'Ergonomist', 'Bookseller', 'Producer, radio', 'Producer, television/film/video', 'Lexicographer', 'Geophysical data processor', 'Secretary, company', 'Archaeologist', 'Plant breeder/geneticist', 'Sub', 'Translator']\n",
      "\n",
      "==================================================\n",
      "Dataset: career_dataset  (4999 rows)\n",
      "'Other' remaining: 830 (16.6%)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career_family</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business And Finance</th>\n",
       "      <td>2498</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>845</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>830</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy And Research</th>\n",
       "      <td>419</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>407</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count  percentage\n",
       "career_family                          \n",
       "Business And Finance   2498        50.0\n",
       "Technology              845        16.9\n",
       "Other                   830        16.6\n",
       "Policy And Research     419         8.4\n",
       "Education               407         8.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of titles still in 'Other' (2 unique):\n",
      "['School Counselor', 'Data Entry Operator']\n"
     ]
    }
   ],
   "source": [
    "dataset_keys = ['ai_impact_jobs_2010_2025', 'ai_impact_future', 'ai_job_trends', 'career_dataset']\n",
    "# checking each dataset that has job titles\n",
    "for key in dataset_keys:\n",
    "    df = cleaned_storage.get(key)\n",
    "    if df is None or 'career_family' not in df.columns:\n",
    "        continue\n",
    "\n",
    "    total = len(df)\n",
    "    other_count = (df['career_family'] == 'Other').sum()\n",
    "    other_pct = other_count / total * 100\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Dataset: {key}  ({total} rows)\")\n",
    "    print(f\"'Other' remaining: {other_count} ({other_pct:.1f}%)\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    display(\n",
    "        df['career_family']\n",
    "        .value_counts()\n",
    "        .to_frame('count')\n",
    "        .assign(percentage=lambda x: (x['count'] / total * 100).round(1))\n",
    "    )\n",
    "\n",
    "    others = df[df['career_family'] == 'Other']['job_title_original'].unique()\n",
    "    if len(others) > 0:\n",
    "        print(f\"\\nSample of titles still in 'Other' ({len(others)} unique):\")\n",
    "        print(list(others[:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48941ab3",
   "metadata": {},
   "source": [
    "## Step 3: Education Level Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef2c9b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ ai_job_trends: renamed required_education → education_level\n",
      "  ai_impact_jobs_2010_2025: no 'education_level' column — skipped\n",
      "✔ ai_impact_future: education levels processed and encoded\n",
      "✔ ai_job_trends: education levels processed and encoded\n",
      "✔ career_dataset: education levels processed and encoded\n",
      "  Coursera: no 'education_level' column — skipped\n",
      "  reviews: no 'education_level' column — skipped\n",
      "  reviews_by_course: no 'education_level' column — skipped\n",
      "✔ cbc_data: education levels processed and encoded\n"
     ]
    }
   ],
   "source": [
    "from Education_engineering import process_education\n",
    "# this code checks the levels of education in the datasets and processes them\n",
    "\n",
    "\n",
    "if 'required_education' in cleaned_storage['ai_job_trends'].columns:\n",
    "    cleaned_storage['ai_job_trends'] = cleaned_storage['ai_job_trends'].rename(\n",
    "        columns={'required_education': 'education_level'}\n",
    "    )\n",
    "    print(\"✔ ai_job_trends: renamed required_education → education_level\")\n",
    "\n",
    "for key, df in cleaned_storage.items():\n",
    "    if 'education_level' in df.columns:\n",
    "        df = process_education(df)\n",
    "        cleaned_storage[key] = df\n",
    "        print(f\"✔ {key}: education levels processed and encoded\")\n",
    "    else:\n",
    "        print(f\"  {key}: no 'education_level' column — skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f855d0b",
   "metadata": {},
   "source": [
    "## Step 4: SKILLS STANDARDISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7092828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting TF-IDF on 'career_dataset'\n",
      "✔ Skill columns detected: ['skills']\n",
      "✔ TF-IDF fitted on 4999 rows\n",
      "  Vocabulary size : 10\n",
      "  Features created: 10\n",
      "  Top 20 features : ['accounting', 'communication', 'counseling', 'data_analysis', 'financial_analysis', 'machine_learning', 'marketing', 'ms_office', 'python', 'sql']\n",
      "  Saved -> models/tfidf_skills.joblib\n",
      "✔ Skill columns detected: ['skills']\n",
      "\n",
      "===== SKILL SUMMARY =====\n",
      "Rows        : 4999\n",
      "Avg skills  : 1.99\n",
      "Max skills  : 3\n",
      "Zero skills : 0 rows\n",
      "Avg active TF-IDF features per row: 1.99\n",
      "Done fitting.\n",
      "\n",
      "Transforming 'ai_impact_jobs_2010_2025'\n",
      "✔ Skill columns detected: ['core_skills', 'ai_skills']\n",
      "✔ TF-IDF transformed 5000 rows → 10 features\n",
      "✔ Skill columns detected: ['core_skills', 'ai_skills']\n",
      "\n",
      "===== SKILL SUMMARY =====\n",
      "Rows        : 5000\n",
      "Avg skills  : 5.99\n",
      "Max skills  : 10\n",
      "Zero skills : 0 rows\n",
      "Avg active TF-IDF features per row: 1.91\n",
      "Done.\n",
      "\n",
      "Transforming 'ai_impact_future'\n",
      " No skill columns found — skipping.\n",
      " No skill columns found — returning zero TF-IDF frame.\n",
      " No skill columns found — skipping.\n",
      "Done.\n",
      "\n",
      "Transforming 'ai_job_trends'\n",
      " No skill columns found — skipping.\n",
      " No skill columns found — returning zero TF-IDF frame.\n",
      " No skill columns found — skipping.\n",
      "Done.\n",
      "\n",
      "Transforming 'Coursera'\n",
      "✔ Skill columns detected: ['gained_skills']\n",
      "✔ TF-IDF transformed 3404 rows → 10 features\n",
      "✔ Skill columns detected: ['gained_skills']\n",
      "\n",
      "===== SKILL SUMMARY =====\n",
      "Rows        : 3404\n",
      "Avg skills  : 14.13\n",
      "Max skills  : 24\n",
      "Zero skills : 0 rows\n",
      "Avg active TF-IDF features per row: 0.52\n",
      "Done.\n",
      "\n",
      "Transforming 'reviews'\n",
      " No skill columns found — skipping.\n",
      " No skill columns found — returning zero TF-IDF frame.\n",
      " No skill columns found — skipping.\n",
      "Done.\n",
      "\n",
      "Transforming 'reviews_by_course'\n",
      " No skill columns found — skipping.\n",
      " No skill columns found — returning zero TF-IDF frame.\n",
      " No skill columns found — skipping.\n",
      "Done.\n",
      "\n",
      "Transforming 'cbc_data'\n",
      "✔ Skill columns detected: ['skills']\n",
      "✔ TF-IDF transformed 999 rows → 10 features\n",
      "✔ Skill columns detected: ['skills']\n",
      "\n",
      "===== SKILL SUMMARY =====\n",
      "Rows        : 999\n",
      "Avg skills  : 3.0\n",
      "Max skills  : 3\n",
      "Zero skills : 0 rows\n",
      "Avg active TF-IDF features per row: 0.17\n",
      "Done.\n",
      "\n",
      "All datasets processed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import skills_engineering\n",
    "\n",
    "# Reload in case the module was edited\n",
    "importlib.reload(skills_engineering)\n",
    "\n",
    "from skills_engineering import process_skills, skills_summary\n",
    "\n",
    "FIT_DATASET = \"career_dataset\"\n",
    "\n",
    "if FIT_DATASET not in cleaned_storage:\n",
    "    raise ValueError(f\"{FIT_DATASET} not found in cleaned_storage.\")\n",
    "\n",
    "tfidf_frames = {}\n",
    "\n",
    "# ---- Fit on the reference dataset first ----\n",
    "print(f\"\\nFitting TF-IDF on '{FIT_DATASET}'\")\n",
    "\n",
    "fit_df = cleaned_storage[FIT_DATASET]\n",
    "\n",
    "df_enriched, tfidf_df, tfidf = process_skills(\n",
    "    fit_df,\n",
    "    is_fit_dataset=True,\n",
    "    save=True\n",
    ")\n",
    "\n",
    "cleaned_storage[FIT_DATASET] = df_enriched\n",
    "tfidf_frames[FIT_DATASET] = tfidf_df\n",
    "\n",
    "if \"skill_count\" in df_enriched.columns:\n",
    "    skills_summary(df_enriched, tfidf_df)\n",
    "\n",
    "print(\"Done fitting.\\n\")\n",
    "\n",
    "\n",
    "# ---- Now apply the fitted vectoriser to the rest ----\n",
    "for name, df in cleaned_storage.items():\n",
    "\n",
    "    if name == FIT_DATASET:\n",
    "        continue\n",
    "\n",
    "    print(f\"Transforming '{name}'\")\n",
    "\n",
    "    df_enriched, tfidf_df, _ = process_skills(\n",
    "        df,\n",
    "        tfidf=tfidf,\n",
    "        is_fit_dataset=False\n",
    "    )\n",
    "\n",
    "    cleaned_storage[name] = df_enriched\n",
    "    tfidf_frames[name] = tfidf_df\n",
    "\n",
    "    if \"skill_count\" in df_enriched.columns:\n",
    "        skills_summary(df_enriched, tfidf_df)\n",
    "\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "print(\"All datasets processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39afd174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Export complete!\n",
      "- All processed datasets saved to: data\\processed/<dataset>.parquet\n",
      "- Model dataset saved to: data\\processed\\model_dataset.parquet and data\\processed\\model_dataset.csv\n",
      "- TF-IDF vectorizer saved to: artifacts/tfidf_vectorizer.joblib\n",
      "- Feature columns saved to: artifacts/feature_columns.json\n",
      "- Model dataset shape: (4999, 26)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# EXPORT PROCESSED OUTPUTS\n",
    "# =========================\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Create output folders\n",
    "PROCESSED_DIR = os.path.join(\"data\", \"processed\")\n",
    "ARTIFACTS_DIR = os.path.join(\"artifacts\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# 2) Save TF-IDF vectorizer artifact (used later in modelling/inference)\n",
    "# (tfidf exists in your notebook after fitting on FIT_DATASET)\n",
    "joblib.dump(tfidf, os.path.join(ARTIFACTS_DIR, \"tfidf_vectorizer.joblib\"))\n",
    "\n",
    "# 3) Save each processed dataset (optional but recommended)\n",
    "for name, df in cleaned_storage.items():\n",
    "    out_path = os.path.join(PROCESSED_DIR, f\"{name}.parquet\")\n",
    "    df.to_parquet(out_path, index=False)\n",
    "\n",
    "# 4) Build ONE \"model-ready\" dataset for Notebook 3\n",
    "# Choose the dataset you will train the career prediction model on:\n",
    "MAIN_DATASET = \"career_dataset\"\n",
    "\n",
    "if MAIN_DATASET not in cleaned_storage:\n",
    "    raise ValueError(f\"{MAIN_DATASET} not found in cleaned_storage. Available: {list(cleaned_storage.keys())}\")\n",
    "\n",
    "model_df = cleaned_storage[MAIN_DATASET].copy()\n",
    "\n",
    "# If TF-IDF features are stored separately in tfidf_frames, append them\n",
    "if \"tfidf_frames\" in globals() and MAIN_DATASET in tfidf_frames:\n",
    "    tfidf_df = tfidf_frames[MAIN_DATASET].copy()\n",
    "\n",
    "    # Avoid duplicate columns if any exist\n",
    "    model_df = model_df.drop(columns=tfidf_df.columns, errors=\"ignore\")\n",
    "\n",
    "    # Concatenate side-by-side (same row order assumed)\n",
    "    model_df = pd.concat(\n",
    "        [model_df.reset_index(drop=True), tfidf_df.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Save model-ready dataset\n",
    "model_parquet = os.path.join(PROCESSED_DIR, \"model_dataset.parquet\")\n",
    "model_csv = os.path.join(PROCESSED_DIR, \"model_dataset.csv\")\n",
    "model_df.to_parquet(model_parquet, index=False)\n",
    "model_df.to_csv(model_csv, index=False)\n",
    "\n",
    "# 5) Save feature list (very useful for Notebook 3 and deployment)\n",
    "feature_cols = [c for c in model_df.columns if c != \"job_title\"]  # adjust if your target column differs\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"feature_columns.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "print(\"✅ Export complete!\")\n",
    "print(f\"- All processed datasets saved to: {PROCESSED_DIR}/<dataset>.parquet\")\n",
    "print(f\"- Model dataset saved to: {model_parquet} and {model_csv}\")\n",
    "print(f\"- TF-IDF vectorizer saved to: {ARTIFACTS_DIR}/tfidf_vectorizer.joblib\")\n",
    "print(f\"- Feature columns saved to: {ARTIFACTS_DIR}/feature_columns.json\")\n",
    "print(f\"- Model dataset shape: {model_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d006c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pathway', 'subject', 'skills', 'competency_type', 'career', 'industry_sector', 'education_level', 'job_title_original', 'job_title_clean', 'career_family']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist()[:10]) # Show the first 10 columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
